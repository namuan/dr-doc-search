{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Doc Search","text":"<p>  </p> <p>Converse with a book (PDF)</p>  <p>See tweet for full demo.</p>  <p>Documentation: https://namuan.github.io/dr-doc-search</p> <p>Source Code: https://github.com/namuan/dr-doc-search</p> <p>PyPI: https://pypi.org/project/dr-doc-search/</p>"},{"location":"#pre-requisites","title":"Pre-requisites","text":"<ul> <li>Tessaract OCR</li> <li>ImageMagick</li> </ul>  <p>Note: If you are using Windows, then make sure that you set the location of ImageMagick executable in the <code>IMCONV</code> environment variable.</p>  <pre><code># For example, if you have installed ImageMagick in PROGRAMFILES\\ImageMagick-7.1.0-Q16-HDRI\nset IMCONV=\"%PROGRAMFILES%\\ImageMagick-7.1.0-Q16-HDRI\\magick\"\n</code></pre>"},{"location":"#installation","title":"Installation","text":"<pre><code>pip install dr-doc-search\n</code></pre>"},{"location":"#example-usage","title":"Example Usage","text":"<p>There are two steps to use this application:</p> <p>1. First, you need to create the index and generate embeddings for the PDF file. Here I'm using a PDF file generated from this page Parable of a Monetary Economy    </p> <p>Before running this, you need to set up your OpenAI API key. You can get it from OpenAI.</p>  <p>From version 1.5.0, you can skip OpenAI and use HuggingFace models to generate embeddings and answers.</p>  <pre><code>export OPENAI_API_KEY=&lt;your-openai-api-key&gt;\n</code></pre> <p>The run the following command to start the training process:</p> <pre><code>dr-doc-search --train -i ~/Downloads/parable-of-a-monetary-economy-heteconomist.pdf\n</code></pre> <p>Use <code>huggingface</code> for generating embeddings:</p> <pre><code>dr-doc-search --train -i ~/Downloads/parable-of-a-monetary-economy-heteconomist.pdf --embedding huggingface\n</code></pre> <p>The training process generates some temporary files in the <code>OutputDir/dr-doc-search/&lt;pdf-name&gt;</code> folder under your home directory. Here is what it looks like:</p> <pre><code> ~/OutputDir/dr-doc-search/parable-of-a-monetary-economy-heteconomist\n$ tree\n.\n\u251c\u2500\u2500 images\n\u2502 \u251c\u2500\u2500 output-1.png\n\u2502 \u251c\u2500\u2500 output-10.png\n\u2502 \u251c\u2500\u2500 output-11.png\n...\n\u2502 \u2514\u2500\u2500 output-9.png\n\u251c\u2500\u2500 index\n\u2502 \u251c\u2500\u2500 docsearch.index\n\u2502 \u2514\u2500\u2500 index.pkl\n\u251c\u2500\u2500 parable-of-a-monetary-economy-heteconomist.pdf\n\u2514\u2500\u2500 scanned\n    \u251c\u2500\u2500 output-1.txt\n    ...\n    \u2514\u2500\u2500 output-9.txt\n</code></pre>  <p>Note: It is possible to change the base of the output directory by providing the <code>--app-dir</code> argument.</p>  <p>2. Now that we have the index, we can use it to start asking questions.</p> <pre><code>dr-doc-search -i ~/Downloads/parable-of-a-monetary-economy-heteconomist.pdf --input-question \"How did the attempt to reduce the debut resulted in decrease in employment?\"\n</code></pre> <p>Or You can open up a web interface (on port :5006) to ask questions:</p> <pre><code>dr-doc-search --web-app -i ~/Downloads/parable-of-a-monetary-economy-heteconomist.pdf\n</code></pre> <p>To use <code>huggingface</code> model, provide the <code>--llm</code> argument:</p> <pre><code>dr-doc-search --web-app -i ~/Downloads/parable-of-a-monetary-economy-heteconomist.pdf --llm huggingface\n</code></pre> <p>There are more options for choose the start and end pages for the PDF file. See the help for more details:</p> <pre><code>dr-doc-search --help\n</code></pre>"},{"location":"#acknowledgements","title":"Acknowledgements","text":"<ul> <li>anton/@abacaj for the idea</li> <li>LangChain</li> <li>HoloViz Panel</li> <li>OpenAI</li> </ul>"},{"location":"#development","title":"Development","text":"<ul> <li>Clone this repository</li> <li>Requirements:</li> <li>Python 3.7+</li> <li> <p>Poetry</p> </li> <li> <p>Create a virtual environment and install the dependencies</p> </li> </ul> <pre><code>poetry install\n</code></pre> <ul> <li>Activate the virtual environment</li> </ul> <pre><code>poetry shell\n</code></pre>"},{"location":"#validating-build","title":"Validating build","text":"<pre><code>make build\n</code></pre>"},{"location":"#release-process","title":"Release process","text":"<p>A release is automatically published when a new version is bumped using <code>make bump</code>. See <code>.github/workflows/build.yml</code> for more details. Once the release is published, <code>.github/workflows/publish.yml</code> will automatically publish it to PyPI.</p>"},{"location":"#disclaimer","title":"Disclaimer","text":"<p>This project is not affiliated with OpenAI. The OpenAI API and GPT-3 language model are not free after the trial period.</p>"},{"location":"api_docs/","title":"API documentation","text":""},{"location":"changelog/","title":"Changelog","text":""},{"location":"changelog/#163-2023-02-18","title":"1.6.3 (2023-02-18)","text":""},{"location":"changelog/#fix","title":"Fix","text":"<ul> <li>Support ImageMagick on Windows</li> </ul>"},{"location":"changelog/#162-2023-02-18","title":"1.6.2 (2023-02-18)","text":""},{"location":"changelog/#fix_1","title":"Fix","text":"<ul> <li>Support Python3.8</li> </ul>"},{"location":"changelog/#161-2023-02-18","title":"1.6.1 (2023-02-18)","text":""},{"location":"changelog/#fix_2","title":"Fix","text":"<ul> <li>Downgrade supported Python version to 3.8.1</li> </ul>"},{"location":"changelog/#160-2023-02-05","title":"1.6.0 (2023-02-05)","text":""},{"location":"changelog/#feat","title":"Feat","text":"<ul> <li>Set temperature when working with OpenAI feat: Store chat in a chat archive which persists between sessions</li> </ul>"},{"location":"changelog/#151-2023-01-29","title":"1.5.1 (2023-01-29)","text":""},{"location":"changelog/#fix_3","title":"Fix","text":"<ul> <li>Fix broken indexing, only worked for first 2 text chunks @Klingefjord</li> <li>Suppress warnings</li> </ul>"},{"location":"changelog/#150-2023-01-29","title":"1.5.0 (2023-01-29)","text":""},{"location":"changelog/#feat_1","title":"Feat","text":"<ul> <li>Allow user to specify a different LLM instead of OpenAI</li> </ul>"},{"location":"changelog/#141-2023-01-14","title":"1.4.1 (2023-01-14)","text":""},{"location":"changelog/#fix_4","title":"Fix","text":"<ul> <li>Ignore empty text chunk as it'll cause error later</li> </ul>"},{"location":"changelog/#140-2023-01-14","title":"1.4.0 (2023-01-14)","text":""},{"location":"changelog/#feat_2","title":"Feat","text":"<ul> <li>Minor improvements in usability</li> <li>Add line-height when displaying answers</li> </ul>"},{"location":"changelog/#130-2023-01-08","title":"1.3.0 (2023-01-08)","text":""},{"location":"changelog/#feat_3","title":"Feat","text":"<ul> <li>Add support for huggingface embedding and allow user to select a different embedding provider from OpenAI</li> <li>Add an option to pre-process a PDF file</li> </ul>"},{"location":"changelog/#fix_5","title":"Fix","text":"<ul> <li>Update Changelog and remove # used for GH issues</li> </ul>"},{"location":"changelog/#120-2023-01-07","title":"1.2.0 (2023-01-07)","text":""},{"location":"changelog/#feat_4","title":"Feat","text":"<ul> <li>Remove duplicate processing of finding similarities</li> </ul>"},{"location":"changelog/#fix_6","title":"Fix","text":"<ul> <li>Only copy pdf if the source path is different</li> </ul>"},{"location":"changelog/#refactor","title":"Refactor","text":"<ul> <li>Simplify code</li> </ul>"},{"location":"changelog/#110-2023-01-07","title":"1.1.0 (2023-01-07)","text":""},{"location":"changelog/#feat_5","title":"Feat","text":"<ul> <li>Provide option to just create a model for provided book</li> <li>WebUI using Holoviz Panel framework</li> </ul>"},{"location":"changelog/#refactor_1","title":"Refactor","text":"<ul> <li>Cleanup</li> <li>Combine workflow steps in a single file to make it easy to port to other projects</li> </ul>"},{"location":"changelog/#101-2023-01-06","title":"1.0.1 (2023-01-06)","text":""},{"location":"changelog/#fix_7","title":"Fix","text":"<ul> <li>Ignore tests (temp) as they can't run on Github Actions due to binary dependencies</li> </ul>"},{"location":"changelog/#100-2023-01-06","title":"1.0.0 (2023-01-06)","text":""},{"location":"changelog/#feat_6","title":"Feat","text":"<ul> <li>Write workflow to generate book summary</li> </ul>"},{"location":"changelog/#0110-2023-01-05","title":"0.11.0 (2023-01-05)","text":""},{"location":"changelog/#feat_7","title":"Feat","text":"<ul> <li>Add steps to convert pdf file to scanned pages of text</li> </ul>"},{"location":"changelog/#0100-2023-01-04","title":"0.10.0 (2023-01-04)","text":""},{"location":"changelog/#feat_8","title":"Feat","text":"<ul> <li>Single version using another method</li> </ul>"},{"location":"changelog/#090-2023-01-04","title":"0.9.0 (2023-01-04)","text":""},{"location":"changelog/#feat_9","title":"Feat","text":"<ul> <li>Add annotated tag</li> </ul>"},{"location":"changelog/#080-2023-01-04","title":"0.8.0 (2023-01-04)","text":""},{"location":"changelog/#feat_10","title":"Feat","text":"<ul> <li>Add poetry_dynamic_versioning to automatic release versioning</li> </ul>"},{"location":"changelog/#070-2023-01-04","title":"0.7.0 (2023-01-04)","text":""},{"location":"changelog/#feat_11","title":"Feat","text":"<ul> <li>Verify input pdf file and set number of pages</li> </ul>"},{"location":"changelog/#060-2023-01-04","title":"0.6.0 (2023-01-04)","text":""},{"location":"changelog/#feat_12","title":"Feat","text":"<ul> <li>Initial commit with a skeleton project</li> </ul>"},{"location":"changelog/#refactor_2","title":"Refactor","text":"<ul> <li>Formatting</li> </ul>"}]}